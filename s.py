import nltk
from nltk.tokenize import word_tokenize

# Test tokenization
text = "Hello, world! How are you doing today?"
tokens = word_tokenize(text)
print(tokens)
